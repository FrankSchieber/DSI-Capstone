{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.4.0 TECHNICAL REPORT     \n",
    "## FRANK SCHIEBER - ATL\n",
    "## DECEMBER 18, 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the U.S. Census Bureau (https://www.census.gov/), the American Community Survey (ACS) (https://www.census.gov/programs-surveys/acs.html) is \"an ongoing survey that provides vital information on a yearly basis about our nation and its people. Information from the survey generates data that help determine how more than $675 billion in federal and state funds are distributed each year.\"\n",
    "\n",
    "What this survey does not do is determine whether data from its social, economic, housing, and demographic subjects can be used to predict raw Democratic or Republican votes in U.S. general elections. Until now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Acquisition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data for the project was acquired from two primary sources:\n",
    "1. U.S. Census Bureau (https://www.census.gov/) - and its American FactFinder Download Center (https://factfinder.census.gov) - social, economic, housing, and demographic data aligned with geography for all 50 U.S. states, District of Columbia and Puerto Rico.\n",
    "\n",
    "2. The American Presidency Project (http://www.presidency.ucsb.edu/index.php) - \"non-profit and non-partisan... leading source of presidential documents\" which provides presidential election data for every U.S. general election since the nation's founding (http://www.presidency.ucsb.edu/elections.php).\n",
    "\n",
    "As Puerto Rico is prohibited from voting in U.S. general elections, data was not downloaded from American FactFinder Download Center for this specific geography. Also, full U.S. census data only from 2007 to 2016 is currently available for download. As U.S. general elections occur once every four years, though data from all years were downloaded, only data from 2008, 2012 and 2016 were applied.\n",
    "\n",
    "U.S. Census Bureau data was downloaded with data representing only that general election year and in the following individual file classifications:\n",
    "    - SOCIAL: ACS_[last 2 digits of year]_1YR_DP02_Est \n",
    "    - ECONOMIC: ACS_[last 2 digits of year]_1YR_DP03_Est\n",
    "    - HOUSING: ACS_[last 2 digits of year]_1YR_DP04_Est\n",
    "    - DEMOGRAPHIC: ACS_[last 2 digits of year]_1YR_DP05_Est\n",
    "    \n",
    "TAPP data was copied and pasted into a .csv file format then saved in its appropriate general election year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets should be uploaded by year with 'header=1' to use the feature description for the header in place of its U.S. Census Bureau identification code. Geographic index codes can be dropped through simple .iloc[:, 2:]. The word \"State\" is used to replace \"Geography\" though that is optional; I used this terminology because U.S. territories and other non-voting geographies are not in consideration. All states are then tagged with a suffix of the last 2 digits of year for future differentiation when concatenating dataframes.\n",
    "\n",
    "Note that there are 4 separate elements of each subject: Estimate, Margin of Error, Percent, and Percent Margin of Error. As I only want to focus on hard estimated values, I created a new dataframe that dropped the last 3 subject elements, only retaining Estimate. I then concatenate that dataframe with the original dataframe's \"State\" column. After, I concatenate all 4 subjects and their estimated values - social, economic, housing, and demographic - so that all the year's data are compiled for that specific election year.\n",
    "\n",
    "I then upload the TAPP file for that specific election year, then drop all columns except three: State, Democratic Votes, and Republican Votes. Like the U.S. Census Bureau data, I tag all states with a suffix of the last 2 digits of year. I rename \"Democratic Votes\" to \"Democrat Votes\" for future alignment with other dataframes, then concatenate the TAPP dataframe with the corresponding ACS dataframe of that year.\n",
    "\n",
    "I repeat all these steps I executed, then create .csv files, for 2016 for both 2012 (Jupyter notebook 5.4.1 ends here) and 2008 (Jupyter notebook 5.4.2 ends here).\n",
    "\n",
    "Now comes the final part of data munging, starting with 2016 dataset. As commas are used in TAPP values, I drop the commas upon uploading the .csv files created at ends of notebooks 5.4.1 and 5.4.2 (sep=\",\",thousands=','). I drop the first 2 columns of index values and set the 'State' column as my index. I examine the dataframe shape (51 rows - good!) and the datatype value counts. Only 'State' should remain an object. I change all other columns in the dataframe that are listed as objects to numeric values, coercing any errors. I then convert any null values to zero and drop any columns where all values are listed as zeroes (fortunately, there are none). I repeat these same steps for both 2012 and 2008."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outcome Variable and Justification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What I feel makes this particular project unique is its approach to outcome variables. Rather than one predicted y variable in these datasets, there are two: 'Democrat Votes' and 'Republican Votes'. Since vote values differ for each state each year, we can anticipate that impact from each feature and observation will be different for each predicted Democrat and Republican vote value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model selection I chose was a simple train-test-split (tts) linear regression model; however, I undertook two different approaches to determine test results. \n",
    "\n",
    "The first approach was to run linear regression for 'Democrat Votes' then 'Republican Votes' using all available estimate features for the 50 states and District of Columbia for each general election year. The tts test scores were startling and telling:\n",
    "\n",
    "**DEMOCRAT VOTES:**\n",
    "\n",
    "2016 = 0.947588358757\n",
    "\n",
    "2012 = 0.95698962335\n",
    "\n",
    "2008 = 0.953805599411\n",
    "\n",
    "**REPUBLICAN VOTES:**\n",
    "\n",
    "2016 = 0.784282331248\n",
    "\n",
    "2012 = 0.943052770498\n",
    "\n",
    "2008 = 0.962388299286\n",
    "\n",
    "It can be inferred that Republican votes are increasingly less beholden to social, economic, housing and demographic U.S. Census Bureau data than Democrat votes over the last decade. This implication may also be realized in election platform and public policy. \n",
    "\n",
    "I then download the dataframes used for each model to individual .csv files (this ends notebook 5.4.3).\n",
    "\n",
    "The second approach was to run linear regression for 'Democrat Votes' and 'Republican Votes' using only selected social features for the 50 states and District of Columbia with all general election years compiled into one dataset. The biggest challenge here was to rename column features so that each year's data would align appropriately and not produce unintentional null values. Once column features for each year all matched, the 2016, 2012 and 2008 dataframes were concatenated with 'Democrat Votes' for each year ultimately yielding 153 rows (50 states plus District of Columbia for 2016, 2012 and 2008) and 35 columns.\n",
    "\n",
    "I then run a tts linear regression on the Democrat dataframe. Shockingly, its test score = 0.991301882889 and examine a scatterplot of predictions. The predictions are startlingly linear (this ends notebook 5.4.4). I do the same for Republican votes, its test score = 0.979822686281 (this ends notebook 5.4.5).\n",
    "\n",
    "Conclusion: using less features, at least these particular social features, produced higher linear regression test scores. Thus, there is a lot of predictive value with these social features, though moreso for 'Democrat Votes' than 'Republican Votes'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Future Research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With more time (and certainly more processing power!), there are seemingly limitless ways to continue exploring this data.\n",
    "\n",
    "For starters, I would try tts linear regression models for both compiled 'Democrat Votes' and compiled 'Republican Votes' using both all U.S. Census Bureau estimate features and other subject features (economic, housing and demographic).\n",
    "\n",
    "I would also like to use more years of U.S. Census Bureau data if available, whether from general election years previous to 2008 or off-years such as 2013-2015.\n",
    "\n",
    "Regarding modeling techniques, logistic regression and classification correlation approaches would be a good way to learn which features truly have the move predictive impact on target 'Democrat Votes' and 'Republican Votes'.\n",
    "\n",
    "There are so many possibilities, yet that is what makes this data science capstone project so fascinating: it feels like even though this took time and effort to produce, I still think I am scratching the surface."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*- Frank Schieber*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
